{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8467698,"sourceType":"datasetVersion","datasetId":5048643}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\ndef conv_block(x, num_filters, act=True):\n    x = L.Conv2D(num_filters, kernel_size=3, padding=\"same\")(x)\n\n    if act == True:\n        x = L.BatchNormalization()(x)\n        x = L.Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(x, num_filters):\n    x = conv_block(x, num_filters)\n    x = conv_block(x, num_filters)\n\n    p = L.MaxPool2D((2, 2))(x)\n    return x, p\n\ndef unet3plus(input_shape, num_classes=1):\n    \"\"\" Inputs \"\"\"\n    inputs = L.Input(input_shape, name=\"input_layer\")\n\n    \"\"\" Encoder \"\"\"\n    e1, p1 = encoder_block(inputs, 64)\n    e2, p2 = encoder_block(p1, 128)\n    e3, p3 = encoder_block(p2, 256)\n    e4, p4 = encoder_block(p3, 512)\n\n    \"\"\" Bottleneck \"\"\"\n    e5 = conv_block(p4, 1024)\n    e5 = conv_block(e5, 1024)\n\n    \"\"\" Decoder 4 \"\"\"\n    e1_d4 = L.MaxPool2D((8, 8))(e1)\n    e1_d4 = conv_block(e1_d4, 64)\n\n    e2_d4 = L.MaxPool2D((4, 4))(e2)\n    e2_d4 = conv_block(e2_d4, 64)\n\n    e3_d4 = L.MaxPool2D((2, 2))(e3)\n    e3_d4 = conv_block(e3_d4, 64)\n\n    e4_d4 = conv_block(e4, 64)\n\n    e5_d4 = L.UpSampling2D((2, 2), interpolation=\"bilinear\")(e5)\n    e5_d4 = conv_block(e5_d4, 64)\n\n    d4 = L.Concatenate()([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n    d4 = conv_block(d4, 64*5)\n\n    \"\"\" Decoder 3 \"\"\" #8000F8\n    e1_d3 = L.MaxPool2D((4, 4))(e1)\n    e1_d3 = conv_block(e1_d3, 64)\n\n    e2_d3 = L.MaxPool2D((2, 2))(e2)\n    e2_d3 = conv_block(e2_d3, 64)\n\n    e3_d3 = conv_block(e3, 64)\n\n    d4_d3 = L.UpSampling2D((2, 2), interpolation=\"bilinear\")(d4)\n    d4_d3 = conv_block(d4_d3, 64)\n\n    e5_d3 = L.UpSampling2D((4, 4), interpolation=\"bilinear\")(e5)\n    e5_d3 = conv_block(e5_d3, 64)\n\n    d3 = L.Concatenate()([e1_d3, e2_d3, e3_d3, d4_d3, e5_d3])\n    d3 = conv_block(d3, 64*5)\n\n    \"\"\" Decoder 2 \"\"\"\n    e1_d2 = L.MaxPool2D((2, 2))(e1)\n    e1_d2 = conv_block(e1_d2, 64)\n\n    e2_d2 = conv_block(e2, 64)\n\n    d3_d2 = L.UpSampling2D((2, 2), interpolation=\"bilinear\")(d3)\n    d3_d2 = conv_block(d3_d2, 64)\n\n    d4_d2 = L.UpSampling2D((4, 4), interpolation=\"bilinear\")(d4)\n    d4_d2 = conv_block(d4_d2, 64)\n\n    e5_d2 = L.UpSampling2D((8, 8), interpolation=\"bilinear\")(e5)\n    e5_d2 = conv_block(e5_d2, 64)\n\n    d2 = L.Concatenate()([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n    d2 = conv_block(d2, 64*5)\n\n    \"\"\" Decoder 1 \"\"\"\n    e1_d1 = conv_block(e1, 64)\n\n    d2_d1 = L.UpSampling2D((2, 2), interpolation=\"bilinear\")(d2)\n    d2_d1 = conv_block(d2_d1, 64)\n\n    d3_d1 = L.UpSampling2D((4, 4), interpolation=\"bilinear\")(d3)\n    d3_d1 = conv_block(d3_d1, 64)\n\n    d4_d1 = L.UpSampling2D((8, 8), interpolation=\"bilinear\")(d4)\n    d4_d1 = conv_block(d4_d1, 64)\n\n    e5_d1 = L.UpSampling2D((16, 16), interpolation=\"bilinear\")(e5)\n    e5_d1 = conv_block(e5_d1, 64)\n\n    d1 = L.Concatenate()([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1])\n    d1 = conv_block(d1, 64*5)\n\n    \"\"\" Output \"\"\"\n    y1 = L.Conv2D(num_classes, kernel_size=3, padding=\"same\")(d1)\n    y1 = L.Activation(\"sigmoid\")(y1)\n    outputs = [y1]\n\n    model = tf.keras.Model(inputs, outputs)\n    return model\n\n\nif __name__ == \"__main__\":\n    input_shape = (256, 256, 3)\n    model = unet3plus(input_shape)\n    model.summary()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T03:43:55.197139Z","iopub.execute_input":"2024-05-21T03:43:55.197483Z","iopub.status.idle":"2024-05-21T03:44:09.355413Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-05-21 03:43:57.015865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-21 03:43:57.015955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-21 03:43:57.158856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,971,777\u001b[0m (102.89 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,971,777</span> (102.89 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m13,056\u001b[0m (51.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,056</span> (51.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nsmooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T03:44:56.725916Z","iopub.execute_input":"2024-05-21T03:44:56.726339Z","iopub.status.idle":"2024-05-21T03:44:56.732805Z","shell.execute_reply.started":"2024-05-21T03:44:56.726307Z","shell.execute_reply":"2024-05-21T03:44:56.731512Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport keras\nimport numpy as np\nimport cv2\nfrom glob import glob\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom sklearn.model_selection import train_test_split\n# from model import unet3plus\n# from metrics import dice_loss, dice_coef\n\nIMG_H = 256\nIMG_W = 256\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef load_dataset(path, split=0.1):\n    \"\"\" Loading the images and masks \"\"\"\n    X = sorted(glob(os.path.join(path, \"images\", \"*\")))\n    Y = sorted(glob(os.path.join(path, \"masks\", \"*\")))\n\n    \"\"\" Spliting the data into training and testing \"\"\"\n    split_size = int(len(X) * split)\n\n    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n\n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\ndef read_image(path):\n    path = path.decode()\n    image = cv2.imread(path, cv2.IMREAD_COLOR)\n    image = cv2.resize(image, (IMG_W, IMG_H))\n    image = image / 255.0\n    image = image.astype(np.float32)\n    return image\n\ndef read_mask(path):\n    path = path.decode()\n    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (IMG_W, IMG_H))\n    mask = mask / 255.0\n    mask = mask.astype(np.float32)\n    mask = np.expand_dims(mask, axis=-1)\n    return mask\n\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape([IMG_H, IMG_W, 3])\n    y.set_shape([IMG_H, IMG_W, 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch=2):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n    return ds\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(\"files\")\n\n    \"\"\" Hyperparameters \"\"\"\n    batch_size = 4\n    lr = 1e-4\n    num_epochs = 100\n    model_path = os.path.join(\"files\", \"model.keras\")\n    csv_path = os.path.join(\"files\", \"log.csv\")\n\n    \"\"\" Dataset \"\"\"\n    dataset_path = \"/kaggle/input/kvasir-seg/Kvasir-SEG\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n\n    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n\n    \"\"\" Model \"\"\"\n    model = unet3plus((IMG_H, IMG_W, 3))\n    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, keras.metrics.MeanIoU(num_classes=2)])\n    # model.summary()\n\n    callbacks = [\n        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-10, verbose=1),\n        CSVLogger(csv_path),\n        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\n    ]\n\n    model.fit(\n        train_dataset,\n        epochs=num_epochs,\n        validation_data=valid_dataset,\n        callbacks=callbacks\n    )","metadata":{"execution":{"iopub.status.busy":"2024-05-21T03:49:38.377722Z","iopub.execute_input":"2024-05-21T03:49:38.378121Z","iopub.status.idle":"2024-05-21T05:09:19.717077Z","shell.execute_reply.started":"2024-05-21T03:49:38.378090Z","shell.execute_reply":"2024-05-21T05:09:19.716164Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: \t800 - 800\nValid: \t100 - 100\nTest: \t100 - 100\nEpoch 1/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.4558 - loss: 0.5442 - mean_io_u_1: 0.4597\nEpoch 1: val_loss improved from inf to 0.98678, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 599ms/step - dice_coef: 0.4560 - loss: 0.5440 - mean_io_u_1: 0.4596 - val_dice_coef: 0.0132 - val_loss: 0.9868 - val_mean_io_u_1: 0.4220 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.5361 - loss: 0.4639 - mean_io_u_1: 0.5326\nEpoch 2: val_loss improved from 0.98678 to 0.65310, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.5362 - loss: 0.4638 - mean_io_u_1: 0.5324 - val_dice_coef: 0.3469 - val_loss: 0.6531 - val_mean_io_u_1: 0.4340 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.5871 - loss: 0.4129 - mean_io_u_1: 0.5599\nEpoch 3: val_loss improved from 0.65310 to 0.40974, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.5872 - loss: 0.4128 - mean_io_u_1: 0.5597 - val_dice_coef: 0.5903 - val_loss: 0.4097 - val_mean_io_u_1: 0.5881 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.6269 - loss: 0.3731 - mean_io_u_1: 0.5935\nEpoch 4: val_loss improved from 0.40974 to 0.38079, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.6269 - loss: 0.3731 - mean_io_u_1: 0.5933 - val_dice_coef: 0.6192 - val_loss: 0.3808 - val_mean_io_u_1: 0.6170 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.6485 - loss: 0.3515 - mean_io_u_1: 0.6062\nEpoch 5: val_loss did not improve from 0.38079\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 571ms/step - dice_coef: 0.6485 - loss: 0.3515 - mean_io_u_1: 0.6060 - val_dice_coef: 0.6142 - val_loss: 0.3858 - val_mean_io_u_1: 0.6325 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.6713 - loss: 0.3287 - mean_io_u_1: 0.6278\nEpoch 6: val_loss improved from 0.38079 to 0.33468, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.6714 - loss: 0.3286 - mean_io_u_1: 0.6276 - val_dice_coef: 0.6653 - val_loss: 0.3347 - val_mean_io_u_1: 0.6593 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.6931 - loss: 0.3069 - mean_io_u_1: 0.6307\nEpoch 7: val_loss did not improve from 0.33468\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.6932 - loss: 0.3068 - mean_io_u_1: 0.6305 - val_dice_coef: 0.6331 - val_loss: 0.3669 - val_mean_io_u_1: 0.6724 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.7136 - loss: 0.2864 - mean_io_u_1: 0.6441\nEpoch 8: val_loss did not improve from 0.33468\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.7137 - loss: 0.2863 - mean_io_u_1: 0.6439 - val_dice_coef: 0.6193 - val_loss: 0.3807 - val_mean_io_u_1: 0.5622 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.7266 - loss: 0.2734 - mean_io_u_1: 0.6631\nEpoch 9: val_loss improved from 0.33468 to 0.29246, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.7268 - loss: 0.2732 - mean_io_u_1: 0.6630 - val_dice_coef: 0.7075 - val_loss: 0.2925 - val_mean_io_u_1: 0.6795 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.7494 - loss: 0.2506 - mean_io_u_1: 0.6723\nEpoch 10: val_loss improved from 0.29246 to 0.27027, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.7495 - loss: 0.2505 - mean_io_u_1: 0.6721 - val_dice_coef: 0.7297 - val_loss: 0.2703 - val_mean_io_u_1: 0.5927 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.7699 - loss: 0.2301 - mean_io_u_1: 0.6716\nEpoch 11: val_loss did not improve from 0.27027\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.7700 - loss: 0.2300 - mean_io_u_1: 0.6715 - val_dice_coef: 0.6939 - val_loss: 0.3061 - val_mean_io_u_1: 0.6071 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.7884 - loss: 0.2116 - mean_io_u_1: 0.6865\nEpoch 12: val_loss did not improve from 0.27027\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.7885 - loss: 0.2115 - mean_io_u_1: 0.6864 - val_dice_coef: 0.7278 - val_loss: 0.2722 - val_mean_io_u_1: 0.6422 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8036 - loss: 0.1964 - mean_io_u_1: 0.6930\nEpoch 13: val_loss did not improve from 0.27027\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8037 - loss: 0.1963 - mean_io_u_1: 0.6929 - val_dice_coef: 0.6965 - val_loss: 0.3035 - val_mean_io_u_1: 0.7297 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8215 - loss: 0.1785 - mean_io_u_1: 0.6944\nEpoch 14: val_loss improved from 0.27027 to 0.26413, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.8216 - loss: 0.1784 - mean_io_u_1: 0.6943 - val_dice_coef: 0.7359 - val_loss: 0.2641 - val_mean_io_u_1: 0.6238 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8411 - loss: 0.1589 - mean_io_u_1: 0.6948\nEpoch 15: val_loss did not improve from 0.26413\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8412 - loss: 0.1588 - mean_io_u_1: 0.6947 - val_dice_coef: 0.7175 - val_loss: 0.2825 - val_mean_io_u_1: 0.5973 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.8522 - loss: 0.1478 - mean_io_u_1: 0.7140\nEpoch 16: val_loss did not improve from 0.26413\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8523 - loss: 0.1477 - mean_io_u_1: 0.7139 - val_dice_coef: 0.7298 - val_loss: 0.2702 - val_mean_io_u_1: 0.5965 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8641 - loss: 0.1359 - mean_io_u_1: 0.7250\nEpoch 17: val_loss improved from 0.26413 to 0.24880, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.8641 - loss: 0.1359 - mean_io_u_1: 0.7248 - val_dice_coef: 0.7512 - val_loss: 0.2488 - val_mean_io_u_1: 0.6720 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8663 - loss: 0.1337 - mean_io_u_1: 0.7348\nEpoch 18: val_loss did not improve from 0.24880\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8663 - loss: 0.1337 - mean_io_u_1: 0.7346 - val_dice_coef: 0.7430 - val_loss: 0.2570 - val_mean_io_u_1: 0.6321 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8715 - loss: 0.1285 - mean_io_u_1: 0.7322\nEpoch 19: val_loss did not improve from 0.24880\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8715 - loss: 0.1285 - mean_io_u_1: 0.7320 - val_dice_coef: 0.6109 - val_loss: 0.3891 - val_mean_io_u_1: 0.5395 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8740 - loss: 0.1260 - mean_io_u_1: 0.7324\nEpoch 20: val_loss improved from 0.24880 to 0.24595, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.8741 - loss: 0.1259 - mean_io_u_1: 0.7323 - val_dice_coef: 0.7540 - val_loss: 0.2460 - val_mean_io_u_1: 0.6948 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8926 - loss: 0.1074 - mean_io_u_1: 0.7524\nEpoch 21: val_loss did not improve from 0.24595\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.8926 - loss: 0.1074 - mean_io_u_1: 0.7522 - val_dice_coef: 0.7491 - val_loss: 0.2509 - val_mean_io_u_1: 0.6158 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9045 - loss: 0.0955 - mean_io_u_1: 0.7571\nEpoch 22: val_loss did not improve from 0.24595\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9045 - loss: 0.0955 - mean_io_u_1: 0.7569 - val_dice_coef: 0.6603 - val_loss: 0.3397 - val_mean_io_u_1: 0.5797 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9060 - loss: 0.0940 - mean_io_u_1: 0.7795\nEpoch 23: val_loss did not improve from 0.24595\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9060 - loss: 0.0940 - mean_io_u_1: 0.7793 - val_dice_coef: 0.7489 - val_loss: 0.2511 - val_mean_io_u_1: 0.7460 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.8944 - loss: 0.1056 - mean_io_u_1: 0.7669\nEpoch 24: val_loss improved from 0.24595 to 0.20417, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.8944 - loss: 0.1056 - mean_io_u_1: 0.7669 - val_dice_coef: 0.7958 - val_loss: 0.2042 - val_mean_io_u_1: 0.7107 - learning_rate: 1.0000e-04\nEpoch 25/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9157 - loss: 0.0843 - mean_io_u_1: 0.7776\nEpoch 25: val_loss did not improve from 0.20417\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9157 - loss: 0.0843 - mean_io_u_1: 0.7775 - val_dice_coef: 0.7195 - val_loss: 0.2805 - val_mean_io_u_1: 0.5974 - learning_rate: 1.0000e-04\nEpoch 26/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9236 - loss: 0.0764 - mean_io_u_1: 0.7947\nEpoch 26: val_loss did not improve from 0.20417\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9236 - loss: 0.0764 - mean_io_u_1: 0.7946 - val_dice_coef: 0.7286 - val_loss: 0.2714 - val_mean_io_u_1: 0.5884 - learning_rate: 1.0000e-04\nEpoch 27/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9191 - loss: 0.0809 - mean_io_u_1: 0.7696\nEpoch 27: val_loss did not improve from 0.20417\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9191 - loss: 0.0809 - mean_io_u_1: 0.7696 - val_dice_coef: 0.7400 - val_loss: 0.2600 - val_mean_io_u_1: 0.7072 - learning_rate: 1.0000e-04\nEpoch 28/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9212 - loss: 0.0788 - mean_io_u_1: 0.7980\nEpoch 28: val_loss did not improve from 0.20417\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 571ms/step - dice_coef: 0.9212 - loss: 0.0788 - mean_io_u_1: 0.7979 - val_dice_coef: 0.7436 - val_loss: 0.2564 - val_mean_io_u_1: 0.6458 - learning_rate: 1.0000e-04\nEpoch 29/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9318 - loss: 0.0682 - mean_io_u_1: 0.8386\nEpoch 29: val_loss did not improve from 0.20417\n\nEpoch 29: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9318 - loss: 0.0682 - mean_io_u_1: 0.8385 - val_dice_coef: 0.7780 - val_loss: 0.2220 - val_mean_io_u_1: 0.6956 - learning_rate: 1.0000e-04\nEpoch 30/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9295 - loss: 0.0705 - mean_io_u_1: 0.8307\nEpoch 30: val_loss improved from 0.20417 to 0.18610, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 580ms/step - dice_coef: 0.9295 - loss: 0.0705 - mean_io_u_1: 0.8306 - val_dice_coef: 0.8139 - val_loss: 0.1861 - val_mean_io_u_1: 0.7201 - learning_rate: 1.0000e-05\nEpoch 31/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9449 - loss: 0.0551 - mean_io_u_1: 0.8629\nEpoch 31: val_loss improved from 0.18610 to 0.18380, saving model to files/model.keras\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 579ms/step - dice_coef: 0.9449 - loss: 0.0551 - mean_io_u_1: 0.8628 - val_dice_coef: 0.8162 - val_loss: 0.1838 - val_mean_io_u_1: 0.7214 - learning_rate: 1.0000e-05\nEpoch 32/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - dice_coef: 0.9485 - loss: 0.0515 - mean_io_u_1: 0.8714\nEpoch 32: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9485 - loss: 0.0515 - mean_io_u_1: 0.8713 - val_dice_coef: 0.8149 - val_loss: 0.1851 - val_mean_io_u_1: 0.7179 - learning_rate: 1.0000e-05\nEpoch 33/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9505 - loss: 0.0495 - mean_io_u_1: 0.8756\nEpoch 33: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9505 - loss: 0.0495 - mean_io_u_1: 0.8755 - val_dice_coef: 0.8137 - val_loss: 0.1863 - val_mean_io_u_1: 0.7123 - learning_rate: 1.0000e-05\nEpoch 34/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9521 - loss: 0.0479 - mean_io_u_1: 0.8782\nEpoch 34: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9521 - loss: 0.0479 - mean_io_u_1: 0.8781 - val_dice_coef: 0.8132 - val_loss: 0.1868 - val_mean_io_u_1: 0.7114 - learning_rate: 1.0000e-05\nEpoch 35/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9536 - loss: 0.0464 - mean_io_u_1: 0.8797\nEpoch 35: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9536 - loss: 0.0464 - mean_io_u_1: 0.8796 - val_dice_coef: 0.8134 - val_loss: 0.1866 - val_mean_io_u_1: 0.7124 - learning_rate: 1.0000e-05\nEpoch 36/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9550 - loss: 0.0450 - mean_io_u_1: 0.8818\nEpoch 36: val_loss did not improve from 0.18380\n\nEpoch 36: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9550 - loss: 0.0450 - mean_io_u_1: 0.8818 - val_dice_coef: 0.8132 - val_loss: 0.1868 - val_mean_io_u_1: 0.7105 - learning_rate: 1.0000e-05\nEpoch 37/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9562 - loss: 0.0438 - mean_io_u_1: 0.8841\nEpoch 37: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9562 - loss: 0.0438 - mean_io_u_1: 0.8841 - val_dice_coef: 0.8149 - val_loss: 0.1851 - val_mean_io_u_1: 0.7190 - learning_rate: 1.0000e-06\nEpoch 38/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9567 - loss: 0.0433 - mean_io_u_1: 0.8831\nEpoch 38: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9567 - loss: 0.0433 - mean_io_u_1: 0.8830 - val_dice_coef: 0.8153 - val_loss: 0.1847 - val_mean_io_u_1: 0.7196 - learning_rate: 1.0000e-06\nEpoch 39/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9569 - loss: 0.0431 - mean_io_u_1: 0.8834\nEpoch 39: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9569 - loss: 0.0431 - mean_io_u_1: 0.8833 - val_dice_coef: 0.8155 - val_loss: 0.1845 - val_mean_io_u_1: 0.7196 - learning_rate: 1.0000e-06\nEpoch 40/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9572 - loss: 0.0428 - mean_io_u_1: 0.8835\nEpoch 40: val_loss did not improve from 0.18380\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9572 - loss: 0.0428 - mean_io_u_1: 0.8834 - val_dice_coef: 0.8156 - val_loss: 0.1844 - val_mean_io_u_1: 0.7193 - learning_rate: 1.0000e-06\nEpoch 41/100\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - dice_coef: 0.9574 - loss: 0.0426 - mean_io_u_1: 0.8835\nEpoch 41: val_loss did not improve from 0.18380\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 572ms/step - dice_coef: 0.9574 - loss: 0.0426 - mean_io_u_1: 0.8834 - val_dice_coef: 0.8157 - val_loss: 0.1843 - val_mean_io_u_1: 0.7191 - learning_rate: 1.0000e-06\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nimport imageio\nfrom glob import glob\nfrom tqdm import tqdm\nimport tensorflow as tf\n# from train import create_dir, load_dataset\n# from metrics import dice_loss, dice_coef\n\nIMG_H = 256\nIMG_W = 256\n\nif __name__ == \"__main__\":\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(f\"results\")\n\n    \"\"\" Load the model \"\"\"\n    model_path = os.path.join(\"files\", \"model.keras\")\n    model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coef\": dice_coef})\n\n    \"\"\" Dataset \"\"\"\n    dataset_path = \"/kaggle/input/kvasir-seg/Kvasir-SEG\"\n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\n    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n\n    \"\"\" Prediction \"\"\"\n    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n        \"\"\" Extracting the name \"\"\"\n        name = x.split(\"/\")[-1].split(\".\")[0]\n\n        \"\"\" Reading the image \"\"\"\n        image = cv2.imread(x, cv2.IMREAD_COLOR)\n        image = cv2.resize(image, (IMG_W, IMG_H))\n        x = image / 255.0\n        x = np.expand_dims(x, axis=0)\n\n        \"\"\" Read Mask \"\"\"\n        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n        mask = cv2.resize(mask, (IMG_W, IMG_H))\n        mask = mask / 255.0\n        mask = np.expand_dims(mask, axis=-1)\n        mask = np.concatenate([mask, mask, mask], axis=-1)\n\n        \"\"\" Prediction \"\"\"\n        pred = model.predict(x, verbose=0)[0]\n        pred = np.concatenate([pred, pred, pred], axis=-1)\n        # pred = (pred > 0.5).astype(np.int32)\n\n        \"\"\" Save final mask \"\"\"\n        line = np.ones((IMG_H, 10, 3)) * 255\n        cat_images = np.concatenate([image, line, mask*255, line, pred*255], axis=1)\n        save_image_path = os.path.join(\"results\",  f\"{name}.jpg\")\n        cv2.imwrite(save_image_path, cat_images)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:09:38.585429Z","iopub.execute_input":"2024-05-21T05:09:38.585895Z","iopub.status.idle":"2024-05-21T05:10:20.329766Z","shell.execute_reply.started":"2024-05-21T05:09:38.585854Z","shell.execute_reply":"2024-05-21T05:10:20.328815Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: \t800 - 800\nValid: \t100 - 100\nTest: \t100 - 100\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]2024-05-21 05:09:57.261074: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.86272, expected 2.0465\n2024-05-21 05:09:57.261136: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.04967, expected 3.23345\n2024-05-21 05:09:57.261154: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.4326, expected 3.61638\n2024-05-21 05:09:57.261184: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.46868, expected 4.65247\n2024-05-21 05:09:57.261200: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.37814, expected 4.56193\n2024-05-21 05:09:57.261212: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.18374, expected 4.36753\n2024-05-21 05:09:57.261224: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 5.54872, expected 4.7325\n2024-05-21 05:09:57.261236: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.78654, expected 4.97032\n2024-05-21 05:09:57.261248: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.0901, expected 3.27388\n2024-05-21 05:09:57.261260: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.11265, expected 4.29643\n2024-05-21 05:09:57.261288: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-21 05:09:57.261302: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-21 05:09:57.261315: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-21 05:09:57.261327: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-21 05:09:57.261339: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-21 05:09:57.261358: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-05-21 05:09:57.307850: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 2.86272, expected 2.0465\n2024-05-21 05:09:57.307908: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.04967, expected 3.23345\n2024-05-21 05:09:57.307919: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.4326, expected 3.61638\n2024-05-21 05:09:57.307928: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.46868, expected 4.65247\n2024-05-21 05:09:57.307937: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 5.37814, expected 4.56193\n2024-05-21 05:09:57.307946: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 5.18374, expected 4.36753\n2024-05-21 05:09:57.307955: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 5.54872, expected 4.7325\n2024-05-21 05:09:57.307964: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.78654, expected 4.97032\n2024-05-21 05:09:57.307973: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.0901, expected 3.27388\n2024-05-21 05:09:57.307982: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.11265, expected 4.29643\n2024-05-21 05:09:57.308015: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[1,64,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,256,256]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-05-21 05:09:57.308035: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-05-21 05:09:57.308051: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-05-21 05:09:57.308062: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-05-21 05:09:57.308074: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-05-21 05:09:57.308095: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n100%|██████████| 100/100 [00:24<00:00,  4.06it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"test_dataset = tf_dataset(test_x, test_y, batch=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:10:25.116579Z","iopub.execute_input":"2024-05-21T05:10:25.117521Z","iopub.status.idle":"2024-05-21T05:10:25.137695Z","shell.execute_reply.started":"2024-05-21T05:10:25.117486Z","shell.execute_reply":"2024-05-21T05:10:25.136639Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"results = model.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:10:28.278206Z","iopub.execute_input":"2024-05-21T05:10:28.278580Z","iopub.status.idle":"2024-05-21T05:10:38.116816Z","shell.execute_reply.started":"2024-05-21T05:10:28.278547Z","shell.execute_reply":"2024-05-21T05:10:38.115816Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - dice_coef: 0.8114 - loss: 0.1886 - mean_io_u_1: 0.7211\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2024-05-21T05:17:18.612262Z","iopub.execute_input":"2024-05-21T05:17:18.612871Z","iopub.status.idle":"2024-05-21T05:17:36.730578Z","shell.execute_reply.started":"2024-05-21T05:17:18.612837Z","shell.execute_reply":"2024-05-21T05:17:36.729472Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/files/ (stored 0%)\n  adding: kaggle/working/files/model.keras (deflated 8%)\n  adding: kaggle/working/files/log.csv (deflated 56%)\n  adding: kaggle/working/results/ (stored 0%)\n  adding: kaggle/working/results/cju35fxqyzt5p0993vusm54qz.jpg (deflated 9%)\n  adding: kaggle/working/results/cju83wwn1k55e0850kw6i2d81.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1fuoa4wmc50835qfd11sp9.jpg (deflated 10%)\n  adding: kaggle/working/results/cju7et17a2vjk0755e743npl1.jpg (deflated 10%)\n  adding: kaggle/working/results/cju2qozsk20cq0855ugrg3cri.jpg (deflated 6%)\n  adding: kaggle/working/results/cju85hguellg50818kwu3s8d1.jpg (deflated 8%)\n  adding: kaggle/working/results/ck2bxskgxxzfv08386xkqtqdy.jpg (deflated 10%)\n  adding: kaggle/working/results/cju7dvl5m2n4t0755hlnnjjet.jpg (deflated 10%)\n  adding: kaggle/working/results/cju5fb86jd1jp0755b1ukbhq5.jpg (deflated 8%)\n  adding: kaggle/working/results/cju84dsvaklpx098750hp83x4.jpg (deflated 8%)\n  adding: kaggle/working/results/cju6vta3kvazg0817qbeppjtm.jpg (deflated 6%)\n  adding: kaggle/working/results/cju7cue9b232j0801qdzk1ykj.jpg (deflated 11%)\n  adding: kaggle/working/results/cju2oq5570avm079959o20op1.jpg (deflated 10%)\n  adding: kaggle/working/results/cju1cfhyg48bb0799cl5pr2jh.jpg (deflated 9%)\n  adding: kaggle/working/results/cju2txjfzv60w098839dcimys.jpg (deflated 12%)\n  adding: kaggle/working/results/cju1csmlc4ht10799b8ymmghg.jpg (deflated 10%)\n  adding: kaggle/working/results/cju34fojcctcf0799ebolbvkn.jpg (deflated 12%)\n  adding: kaggle/working/results/cju5wkonqlrl409877y8zvnub.jpg (deflated 7%)\n  adding: kaggle/working/results/cju2rn0hasxri0835nfy3buay.jpg (deflated 11%)\n  adding: kaggle/working/results/cju8alhigqn2h0801zksudldd.jpg (deflated 7%)\n  adding: kaggle/working/results/cju89z6pqpqfx0817mfv8ixjc.jpg (deflated 13%)\n  adding: kaggle/working/results/cju15wdt3zla10801odjiw7sy.jpg (deflated 8%)\n  adding: kaggle/working/results/cju183od81ff608017ekzif89.jpg (deflated 8%)\n  adding: kaggle/working/results/cju17g6ykn1cs0993dww6qdi8.jpg (deflated 7%)\n  adding: kaggle/working/results/cju2zrojo9kcd0878ld2epejq.jpg (deflated 12%)\n  adding: kaggle/working/results/cju33za6l2qy70988jhrlp2ev.jpg (deflated 10%)\n  adding: kaggle/working/results/cju42u5bjlvi10801dc13sskp.jpg (deflated 10%)\n  adding: kaggle/working/results/cju8cj10qsrau0871o2dr6ai1.jpg (deflated 11%)\n  adding: kaggle/working/results/cju83h9ysjwe808716nt35oah.jpg (deflated 11%)\n  adding: kaggle/working/results/cju7d2q1k27nf08715zshsckt.jpg (deflated 10%)\n  adding: kaggle/working/results/cju0sr5ghl0nd08789uzf1raf.jpg (deflated 6%)\n  adding: kaggle/working/results/cju7ev2b12owa08500bpfpwyw.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1ejj7dvqfa0835ra184v5m.jpg (deflated 8%)\n  adding: kaggle/working/results/cju2wxv0hxs2f09884w48v8fi.jpg (deflated 10%)\n  adding: kaggle/working/results/cju0sxqiclckk08551ycbwhno.jpg (deflated 11%)\n  adding: kaggle/working/results/cju2xf8e5y2wm08359vcgk09b.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1euuc65wm00799m4sjdnnn.jpg (deflated 11%)\n  adding: kaggle/working/results/cju3uz4o6gr9z0850lhxyxvsj.jpg (deflated 8%)\n  adding: kaggle/working/results/cju439oazm2fu0871ma0vvrft.jpg (deflated 8%)\n  adding: kaggle/working/results/cju0vtox5ain6099360pu62rp.jpg (deflated 13%)\n  adding: kaggle/working/results/cju41p90plcsx08018cnzpndc.jpg (deflated 8%)\n  adding: kaggle/working/results/cju7db7lp2f400755tntd1ohf.jpg (deflated 8%)\n  adding: kaggle/working/results/cju326h4v1gxw08352px40p7r.jpg (deflated 6%)\n  adding: kaggle/working/results/cju6wi3akvn8r0801px8eligc.jpg (deflated 8%)\n  adding: kaggle/working/results/cju8cwy02t9eq08185qn12c02.jpg (deflated 10%)\n  adding: kaggle/working/results/cju3xiic0ilzp0850lusrb42j.jpg (deflated 15%)\n  adding: kaggle/working/results/cju3v11mrgwwb0755u242ygye.jpg (deflated 11%)\n  adding: kaggle/working/results/cju40m0rjkpw80871z6n6yg1u.jpg (deflated 7%)\n  adding: kaggle/working/results/cju5ca9hcatkc0801jzwe7tfx.jpg (deflated 7%)\n  adding: kaggle/working/results/cju88cddensj00987788yotmg.jpg (deflated 11%)\n  adding: kaggle/working/results/cju7bmi1v1pnj0987pa52jjok.jpg (deflated 9%)\n  adding: kaggle/working/results/cju8bljw9rqk20801kr54akrl.jpg (deflated 8%)\n  adding: kaggle/working/results/cju5h57xedz5h0755mjpc8694.jpg (deflated 6%)\n  adding: kaggle/working/results/cju7dizi82h2i0755doucgnt3.jpg (deflated 8%)\n  adding: kaggle/working/results/cju41kd7yl4nm0850gil5qqwh.jpg (deflated 11%)\n  adding: kaggle/working/results/cju6vqarjv7yo0987q4b1btk1.jpg (deflated 10%)\n  adding: kaggle/working/results/cju43gfosm63n08714rpih8pe.jpg (deflated 9%)\n  adding: kaggle/working/results/cju1b75x63ddl0799sdp0i2j3.jpg (deflated 11%)\n  adding: kaggle/working/results/cju87z6o6nh73085045bzsx6o.jpg (deflated 11%)\n  adding: kaggle/working/results/cju8402x1kcy70801t6kz6bdi.jpg (deflated 7%)\n  adding: kaggle/working/results/cju7agj961l2r0818z29iq8yn.jpg (deflated 12%)\n  adding: kaggle/working/results/cju8a84g0q76m0818hwiggkod.jpg (deflated 7%)\n  adding: kaggle/working/results/cju5xopi0md7q0871r1sjc1av.jpg (deflated 9%)\n  adding: kaggle/working/results/cju5wuhm1lwm40987vugqn3vv.jpg (deflated 9%)\n  adding: kaggle/working/results/cju33mirdc8mj0799k33wzoes.jpg (deflated 7%)\n  adding: kaggle/working/results/cju5wqonpm0e60801z88ewmy1.jpg (deflated 9%)\n  adding: kaggle/working/results/cju7b3f5h1sm40755i572jden.jpg (deflated 9%)\n  adding: kaggle/working/results/cju5u6wf0kh1t0755bg1ssixv.jpg (deflated 6%)\n  adding: kaggle/working/results/cju1hyolc7aqu0878rrkfn1lr.jpg (deflated 10%)\n  adding: kaggle/working/results/cju2wx0gh7fpz0878wwyd9ep8.jpg (deflated 9%)\n  adding: kaggle/working/results/cju87kbcen2av0987usezo8kn.jpg (deflated 9%)\n  adding: kaggle/working/results/cju88l66no10s0850rsda7ej1.jpg (deflated 9%)\n  adding: kaggle/working/results/cju8bm24yrrdp081829mbo8ic.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1c8ffau5770835g0g343o8.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1g4nsb6ngy0799l4ezm8ab.jpg (deflated 9%)\n  adding: kaggle/working/results/cju3u4lxmg59o0755rz42b9en.jpg (deflated 8%)\n  adding: kaggle/working/results/cju85ia1slh220987y7c20sm2.jpg (deflated 9%)\n  adding: kaggle/working/results/cju3x2s11ibzi0817kk284k0j.jpg (deflated 9%)\n  adding: kaggle/working/results/cju7dsrtb2f8i085064kwugfk.jpg (deflated 11%)\n  adding: kaggle/working/results/cju3tp94kfstl08181awh6z49.jpg (deflated 7%)\n  adding: kaggle/working/results/cju302fqq9spc0878rrygyzzz.jpg (deflated 7%)\n  adding: kaggle/working/results/cju88q6h6obpd0871ckmiabbo.jpg (deflated 8%)\n  adding: kaggle/working/results/cju1hirfi7ekp0855q0vgm9qq.jpg (deflated 9%)\n  adding: kaggle/working/results/cju8418jhkf7d0818ga2v0xq0.jpg (deflated 9%)\n  adding: kaggle/working/results/cju7dymur2od30755eg8yv2ht.jpg (deflated 10%)\n  adding: kaggle/working/results/cju87zv8lni0o0850hbbecbq6.jpg (deflated 9%)\n  adding: kaggle/working/results/cju5eq8c8ck690850vix98hv3.jpg (deflated 7%)\n  adding: kaggle/working/results/cjyzkmjy8evns070165gf9dmq.jpg (deflated 11%)\n  adding: kaggle/working/results/cju1aqqv02qwz0878a5cyhr67.jpg (deflated 9%)\n  adding: kaggle/working/results/cju30gxjq0djk0988jytm49rs.jpg (deflated 10%)\n  adding: kaggle/working/results/cju40sdwukv3k0755y99ug1k8.jpg (deflated 7%)\n  adding: kaggle/working/results/cju87tyddnnad0755bj0wxahe.jpg (deflated 7%)\n  adding: kaggle/working/results/cju6xlygpw7bs0818n691jsq4.jpg (deflated 8%)\n  adding: kaggle/working/results/cju7efffp2ivf0817etg3jehl.jpg (deflated 7%)\n  adding: kaggle/working/results/cju2tjrog4jy30878pawyazqc.jpg (deflated 10%)\n  adding: kaggle/working/results/cju42qet0lsq90871e50xbnuv.jpg (deflated 11%)\n  adding: kaggle/working/results/cju5huurrecm70801y680y13m.jpg (deflated 10%)\n  adding: kaggle/working/results/cju30525w04r10835ygp257sb.jpg (deflated 10%)\n  adding: kaggle/working/results/cju83syhdk6gs0801rf1rekdl.jpg (deflated 9%)\n  adding: kaggle/working/results/cju5fs6j6d8350801vglraq4u.jpg (deflated 7%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n","output_type":"stream"}],"execution_count":9}]}